/*
 * Copyright (c) 2025 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://edgeimpulse.com/legal/terms-of-service) or Enterprise Terms of
 * Service (https://edgeimpulse.com/legal/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */
// Generated on: 21.11.2025 10:30:08

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#define STRINGIZE(x) #x
#define STRINGIZE_VALUE_OF(x) STRINGIZE(x)

#if defined (__GNUC__)  /* GNU compiler */
#define ALIGN(X) __attribute__((aligned(X)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (_MSC_VER)
#define ALIGN(X) __declspec(align(X))
#elif defined (__TASKING__) /* TASKING Compiler */
#define ALIGN(X) __align(X)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ARMCC_VERSION) /* Arm Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__ICCARM__) /* IAR Compiler */
#define ALIGN(x) __attribute__((aligned(x)))
#define DEFINE_SECTION(x) __attribute__((section(x)))
#elif defined (__clang__) /* LLVM/Clang Compiler */
#define ALIGN(X) __ALIGNED(x)
#define DEFINE_SECTION(x) __attribute__((section(x)))
#endif

#if defined(EI_MODEL_SECTION) && (defined(__GNUC__) || defined(__clang__))
#define MODEL_SECTION(X) __attribute__((section(STRINGIZE_VALUE_OF(X))))
#else
#define MODEL_SECTION(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 10
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 20
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 7952;
#else
constexpr int kTensorArenaSize = 6928;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
#if defined (EI_TENSOR_ARENA_LOCATION)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) DEFINE_SECTION(STRINGIZE_VALUE_OF(EI_TENSOR_ARENA_LOCATION));
#else
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#endif
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};

enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_DEPTHWISE_CONV_2D, OP_MEAN, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};

struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];

namespace g0 {
const TfArray<2, int> tensor_dimension0 = { 2, { 1,637 } };
const TfArray<1, float> quant0_scale = { 1, { 0.0441405288875103, } };
const TfArray<1, int> quant0_zero = { 1, { -12 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data1[4] = { 1, 49, 13, 1, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(8) int32_t tensor_data2[2] = { 1, 2, };
const TfArray<1, int> tensor_dimension2 = { 1, { 2 } };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data3[7] = { 413, -85, -1001, 1719, 297, 293, -878, };
const TfArray<1, int> tensor_dimension3 = { 1, { 7 } };
const TfArray<1, float> quant3_scale = { 1, { 0.00035034830216318369, } };
const TfArray<1, int> quant3_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant3 = { (TfLiteFloatArray*)&quant3_scale, (TfLiteIntArray*)&quant3_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data4[7*24] = { 
  46, 44, -67, -104, 43, -40, -35, 19, -49, 39, 40, -94, 64, -7, 9, -114, -68, -93, 9, -93, 32, -49, -95, 38, 
  -68, -46, -28, 53, 0, -61, -72, 11, -70, 49, 27, -82, -44, -55, 49, 42, 42, -60, 16, -73, -48, -87, 51, 24, 
  -3, -45, -72, -58, 35, 33, 63, -112, -67, -16, -91, 48, -104, -88, -77, 49, 61, 57, 36, -32, -63, -51, 13, -50, 
  57, -68, -85, -86, 44, 19, 56, 16, -96, -95, -33, 30, -52, 23, -14, 0, -29, -43, -70, -76, 41, -54, -127, -52, 
  3, 12, 26, -45, -125, -112, -43, 19, 30, -39, 31, -47, 65, 37, -9, -71, -69, -67, 44, 16, 26, 75, -34, -77, 
  -87, -74, 74, 58, 41, 36, -35, -68, -40, -67, 34, -32, -10, -49, -105, -69, -83, 58, 47, 68, -107, 11, -47, 54, 
  -23, 66, 41, 43, -20, 8, 32, -23, 63, 38, -20, 20, 43, -30, 35, 37, 32, 2, -46, 40, -28, 55, 45, -17, 
};
const TfArray<2, int> tensor_dimension4 = { 2, { 7,24 } };
const TfArray<1, float> quant4_scale = { 1, { 0.01547516230493784, } };
const TfLiteAffineQuantization quant4 = { (TfLiteFloatArray*)&quant4_scale, (TfLiteIntArray*)&g0::quant3_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data5[24] = { -19, -360, 425, 1374, 2507, 1969, 503, -3178, -115, -883, 177, 274, -786, -1734, -610, 255, -292, 1419, -73, 471, -935, -220, -73, 1604, };
const TfArray<1, int> tensor_dimension5 = { 1, { 24 } };
const TfArray<24, float> quant5_scale = { 24, { 0.00079698412446305156, 0.0014717094600200653, 0.0014228253858163953, 0.00083100982010364532, 0.00093973695766180754, 0.0013615235220640898, 0.001169996801763773, 0.00083863257896155119, 0.0017310556722804904, 0.00091622769832611084, 0.0011409966973587871, 0.0014442639658227563, 0.0013610112946480513, 0.0015215027378872037, 0.00074963213410228491, 0.00074145401595160365, 0.00089709862368181348, 0.00089356157695874572, 0.00095581624191254377, 0.0013360296143218875, 0.001150970347225666, 0.0015489273937419057, 0.00074220361420884728, 0.0010101048974320292, } };
const TfArray<24, int> quant5_zero = { 24, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant5 = { (TfLiteFloatArray*)&quant5_scale, (TfLiteIntArray*)&quant5_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data6[24*1*1*24] = { 
  /* [0][0][][] */ -48,4,-77,97,26,-44,-28,-26,6,28,36,-11,-92,-84,-29,127,108,5,9,-6,31,-1,-21,1, 
  /* [1][0][][] */ -18,-37,19,-19,-127,-28,-23,16,56,-77,-33,9,26,15,-14,3,-10,-35,-50,45,12,24,59,9, 
  /* [2][0][][] */ 26,-12,25,62,-105,-44,5,25,0,-127,-48,-4,27,63,62,-26,-51,-6,-52,68,-31,-56,33,-36, 
  /* [3][0][][] */ -7,-45,108,-90,-47,87,-41,124,2,-88,-69,24,74,42,127,-89,-64,-56,-127,57,-52,-108,53,-82, 
  /* [4][0][][] */ -127,43,42,-36,75,-8,-22,68,-38,62,-20,-32,-32,-67,77,56,18,-27,44,-43,26,-92,-5,-104, 
  /* [5][0][][] */ -59,-2,74,-33,-21,-57,-33,57,-28,-13,8,-61,34,-29,83,30,4,5,85,-17,-44,-86,39,-127, 
  /* [6][0][][] */ -13,-33,42,5,-27,-68,-60,-17,9,3,80,-55,-17,-23,-7,35,18,5,127,-15,-76,-6,65,-38, 
  /* [7][0][][] */ 96,38,-73,94,34,54,85,-43,-2,110,-87,83,-127,33,-35,45,94,21,-15,12,68,16,-72,109, 
  /* [8][0][][] */ 10,-37,15,43,-127,-29,-11,2,33,-81,-27,-2,13,33,-5,-11,-28,-9,-26,48,-27,2,46,4, 
  /* [9][0][][] */ -84,-71,86,-127,-32,95,-63,112,88,11,-80,35,87,0,-3,-55,-8,-116,-65,62,44,53,86,6, 
  /* [10][0][][] */ 3,37,-36,-52,42,42,94,13,-42,70,-127,21,-51,2,73,-6,22,-7,-32,29,88,-66,-48,-15, 
  /* [11][0][][] */ -7,-25,26,12,-38,-58,-27,-3,27,-25,59,-47,-11,-2,10,7,6,5,127,12,-81,-13,58,-33, 
  /* [12][0][][] */ -10,-6,-31,103,-121,-36,0,-23,52,-127,-83,9,12,45,-25,-1,-7,-10,-40,110,50,26,29,30, 
  /* [13][0][][] */ 79,-4,-72,127,-6,-16,44,-81,0,-28,10,33,-47,45,-22,19,-7,53,2,17,4,12,-17,39, 
  /* [14][0][][] */ 12,-99,89,-100,-96,127,-71,92,93,2,-84,48,33,27,-44,-27,30,-109,-112,24,-7,31,59,17, 
  /* [15][0][][] */ -12,-63,104,-127,20,51,-100,50,64,1,80,-5,52,32,7,-96,-8,-107,107,21,-77,-9,83,-8, 
  /* [16][0][][] */ -22,-46,78,-127,28,43,-71,44,76,11,40,9,66,31,-5,-126,-32,-90,109,21,-28,17,86,12, 
  /* [17][0][][] */ -38,42,60,-30,-6,-60,3,57,-10,-57,-15,-45,91,3,111,-55,-62,27,109,9,-27,-112,55,-127, 
  /* [18][0][][] */ -3,90,-54,-36,70,24,127,-29,-33,81,-64,15,0,-12,63,-51,-28,40,113,34,42,-74,-30,-44, 
  /* [19][0][][] */ 22,-24,30,58,-122,-48,-1,20,1,-127,-37,-20,36,55,55,-20,-53,7,-34,63,-38,-51,39,-44, 
  /* [20][0][][] */ 37,-3,-82,127,13,-15,3,-60,4,9,-4,26,-72,-11,-54,68,66,31,-3,7,34,-1,-35,33, 
  /* [21][0][][] */ 26,-21,3,110,-127,-42,6,-16,27,-118,-28,-9,-1,66,-3,-21,-46,9,-21,74,-35,-8,38,2, 
  /* [22][0][][] */ -5,-76,89,-81,-81,75,-70,65,112,-46,-17,19,89,63,1,-127,-73,-105,23,75,-62,10,105,-2, 
  /* [23][0][][] */ -93,18,57,-84,41,40,-12,98,-43,41,-100,16,5,-36,127,15,12,-44,-96,-13,49,-92,2,-93, 
};
const TfArray<4, int> tensor_dimension6 = { 4, { 24,1,1,24 } };
const TfArray<24, float> quant6_scale = { 24, { 0.017817897722125053, 0.032902497798204422, 0.031809613108634949, 0.018578598275780678, 0.021009372547268867, 0.030439108610153198, 0.026157211512327194, 0.018749017268419266, 0.038700610399246216, 0.020483784377574921, 0.02550886757671833, 0.032288908958435059, 0.030427657067775726, 0.034015707671642303, 0.016759265214204788, 0.016576429829001427, 0.020056122913956642, 0.019977046176791191, 0.021368851885199547, 0.029869150370359421, 0.025731844827532768, 0.034628830850124359, 0.016593188047409058, 0.022582564502954483, } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&g0::quant5_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data7[24] = { 6484, -1247, -7144, -3644, -1011, -107, -6738, 7276, -2145, -788, -1034, -1466, -1044, -147, 3865, -3143, 5216, 5272, -5203, -3365, -1093, 1894, -3820, 11069, };
const TfArray<24, float> quant7_scale = { 24, { 0.00025975698372349143, 0.00021278458007145673, 0.00020338382455520332, 0.00044520830851979554, 0.00018337754590902478, 0.001249052002094686, 0.00019330100622028112, 0.00024487762129865587, 0.0003306978615000844, 0.0011459419038146734, 0.00038630602648481727, 0.00025934007135219872, 0.00037507893284782767, 0.0011858078651130199, 0.0003068933729082346, 0.0004100302467122674, 0.00024065407342277467, 0.00022001669276505709, 0.00036738804192282259, 0.00020173421944491565, 0.00059463235083967447, 0.00024389565805904567, 0.00024422109709121287, 0.00010919191117864102, } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&g0::quant5_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data8[1*3*3*24] = { 
  /* [0][0][][] */ -95,42,71,82,-1,-83,86,-56,107,102,-95,84,-41,87,-37,85,-127,-85,116,70,111,51,90,-114, -89,21,81,110,45,-59,102,-90,90,97,39,125,-5,127,-101,90,-89,-126,82,18,127,-17,90,-82, -45,-87,64,64,-89,66,61,-21,18,62,49,127,-3,32,-41,42,-50,-100,56,-12,120,-49,-76,-11, 
  /* [0][1][][] */ -102,69,127,70,41,60,51,-92,-127,96,-79,-64,-127,102,-91,64,-101,-57,78,127,78,127,96,-98, -127,23,118,93,0,101,104,-127,28,87,72,96,1,90,-127,109,-92,-119,97,101,117,-19,-34,-109, -66,-111,47,26,-127,127,110,-68,2,113,76,83,24,50,-2,59,-63,-93,-25,52,116,-78,-60,-58, 
  /* [0][2][][] */ -52,48,91,100,33,46,66,-57,59,126,-127,-15,48,72,-79,127,-125,-55,76,83,71,108,127,-112, -106,4,91,127,3,81,91,-114,104,127,99,85,71,54,-67,93,-85,-94,127,53,103,-13,33,-81, -75,-127,46,-67,-44,93,127,-76,87,96,101,76,44,-65,16,70,-20,-127,20,66,69,-95,-24,-127, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 1,3,3,24 } };
const TfArray<24, float> quant8_scale = { 24, { 0.0087918573990464211, 0.0072020073421299458, 0.0068838251754641533, 0.015068730339407921, 0.0062066828832030296, 0.042276002466678619, 0.006542556919157505, 0.0082882437855005264, 0.011192956008017063, 0.038786090910434723, 0.013075096532702446, 0.0087777469307184219, 0.012695098295807838, 0.040135413408279419, 0.010387257672846317, 0.013878077268600464, 0.0081452913582324982, 0.0074467887170612812, 0.012434788979589939, 0.0068279914557933807, 0.020126206800341606, 0.0082550076767802238, 0.0082660224288702011, 0.0036957610864192247, } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&g0::quant5_zero, 3 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data9[24] = { 5613, 1471, 182, -1640, -2161, -5203, 537, 2586, -4947, -8529, -9715, 72, 5614, -10566, 570, 1025, 4040, -2424, 142, -4122, -592, 13791, -7407, 1904, };
const TfArray<24, float> quant9_scale = { 24, { 0.0001955055195139721, 0.00023558492830488831, 0.00020314955327194184, 7.2967661253642291e-05, 0.00019747739133890718, 6.4392705098725855e-05, 0.00012388391769491136, 0.00010134070907952264, 0.00014612049562856555, 6.4345054852310568e-05, 0.00010250299965264276, 0.00011055065260734409, 7.1088914410211146e-05, 4.3413532694103196e-05, 0.00016136834165081382, 0.00013441246119327843, 0.00018527507199905813, 0.00015264327521435916, 0.0001804403291316703, 0.00014603699673898518, 0.00015252281446009874, 3.303002449683845e-05, 0.0001508460845798254, 0.00013585416309069842, } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&g0::quant5_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data10[24*1*1*16] = { 
  /* [0][0][][] */ 41,-117,-38,31,-24,-18,13,-7,-88,-54,-10,-127,-8,-44,124,-61, 
  /* [1][0][][] */ -86,-127,-26,-4,-8,-32,-30,-29,21,114,34,41,43,19,-70,53, 
  /* [2][0][][] */ -4,24,-63,30,78,-5,-52,-47,64,19,-29,-127,51,21,-10,64, 
  /* [3][0][][] */ 64,49,-54,-70,-63,-28,5,127,32,-64,115,-69,-38,38,-110,32, 
  /* [4][0][][] */ 112,-77,37,34,46,-20,127,-75,11,52,-61,31,1,72,-84,46, 
  /* [5][0][][] */ 88,84,-84,49,57,37,-89,-100,34,-119,-15,-127,9,9,-72,-53, 
  /* [6][0][][] */ -127,-25,58,82,-49,84,15,46,-31,31,-99,-111,-53,-52,59,76, 
  /* [7][0][][] */ -57,79,40,-29,45,-19,56,-86,-23,-24,-17,-96,21,127,41,-1, 
  /* [8][0][][] */ -13,47,-33,33,73,-9,-127,33,74,-33,88,-10,-15,-2,14,69, 
  /* [9][0][][] */ -16,82,-4,-45,-64,-80,-34,37,94,16,22,111,-58,91,-12,-127, 
  /* [10][0][][] */ 85,-17,0,102,15,30,85,44,20,-91,4,-10,45,127,-18,24, 
  /* [11][0][][] */ 105,-23,50,-9,30,-24,-97,6,-38,-127,-112,5,41,-19,81,-50, 
  /* [12][0][][] */ 7,32,110,47,-19,-22,-76,76,-4,69,-100,-45,15,56,-127,14, 
  /* [13][0][][] */ 57,-63,28,76,85,66,-32,-127,-107,-92,-27,-24,-54,-40,26,-107, 
  /* [14][0][][] */ 19,-31,-84,29,13,-63,-20,-16,-127,20,-12,65,50,63,1,33, 
  /* [15][0][][] */ 42,-114,-127,45,19,-111,22,4,53,-78,-19,16,46,-6,46,34, 
  /* [16][0][][] */ -36,-4,-64,127,-115,50,40,-10,-51,72,23,-116,-23,-74,-40,-35, 
  /* [17][0][][] */ 42,58,63,-17,-30,25,48,76,-96,-127,37,-12,-12,-37,6,9, 
  /* [18][0][][] */ -39,17,-7,69,3,-94,47,-34,-11,127,-58,-5,39,-80,-45,42, 
  /* [19][0][][] */ 11,-31,-127,-54,96,14,1,64,127,-30,93,-27,59,60,-27,71, 
  /* [20][0][][] */ 33,-17,-35,-127,-21,-4,12,28,15,-6,31,11,-70,-7,24,22, 
  /* [21][0][][] */ 50,79,127,-61,40,-102,-2,-17,-93,-38,-101,27,82,76,41,-28, 
  /* [22][0][][] */ -2,18,-62,93,61,45,45,42,-6,127,-8,1,-30,61,-20,88, 
  /* [23][0][][] */ 7,-14,-127,-55,39,65,82,92,-116,51,56,77,10,-73,37,-21, 
};
const TfArray<4, int> tensor_dimension10 = { 4, { 24,1,1,16 } };
const TfArray<24, float> quant10_scale = { 24, { 0.0065439431928098202, 0.0078854775056242943, 0.0067998035810887814, 0.0024423669092357159, 0.0066099450923502445, 0.0021553467959165573, 0.0041466313414275646, 0.003392067039385438, 0.0048909317702054977, 0.0021537519060075283, 0.0034309711772948503, 0.0037003413308411837, 0.0023794816806912422, 0.0014531337656080723, 0.0054013063199818134, 0.0044990414753556252, 0.0062015103176236153, 0.0051092617213726044, 0.0060396823100745678, 0.0048881368711590767, 0.0051052295602858067, 0.0011055779177695513, 0.005049106664955616, 0.0045472979545593262, } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&g0::quant5_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data11[16] = { -5814, 1879, 1345, 3452, -3061, -2858, 926, -1266, -1183, -4194, -458, -5066, -9589, 3870, 1714, -955, };
const TfArray<1, int> tensor_dimension11 = { 1, { 16 } };
const TfArray<16, float> quant11_scale = { 16, { 0.00015192570572253317, 0.00023592147044837475, 0.00046370859490707517, 0.00054123770678415895, 0.00023143802536651492, 0.00017937153461389244, 0.00020302535267546773, 0.00041944696567952633, 0.00032250615186057985, 0.00024715965264476836, 0.00034651171881705523, 0.00033605925273150206, 0.00016819950542412698, 0.00021200929768383503, 0.0003592624852899462, 0.00021560321329161525, } };
const TfArray<16, int> quant11_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data12[1*3*3*16] = { 
  /* [0][0][][] */ -71,-127,-17,-35,27,121,127,-106,-127,-11,21,127,-5,-36,-72,-70, 84,-32,-32,-44,0,45,-16,-29,57,47,63,37,127,-45,-127,83, -26,55,29,17,41,-8,-113,24,75,-44,-2,29,2,-14,49,33, 
  /* [0][1][][] */ -57,-89,46,-70,90,91,69,-48,-27,-34,-85,121,86,-32,4,-104, 115,20,-54,-63,-2,127,-43,59,-2,127,71,5,112,-34,-97,127, 73,16,-14,35,77,-43,-25,43,13,-99,-14,24,45,20,37,-21, 
  /* [0][2][][] */ -1,-40,127,-127,127,62,50,-63,-28,10,-127,42,30,-127,32,-15, 52,74,-27,-29,9,65,-74,127,-22,86,48,39,113,-28,-51,71, 127,-28,-32,21,8,-78,28,46,80,-82,-39,14,86,5,12,-13, 
};
const TfArray<4, int> tensor_dimension12 = { 4, { 1,3,3,16 } };
const TfArray<16, float> quant12_scale = { 16, { 0.0046966704539954662, 0.0072933370247483253, 0.014335206709802151, 0.016731962561607361, 0.007154734805226326, 0.0055451379157602787, 0.0062763779424130917, 0.012966891750693321, 0.0099700381979346275, 0.0076407571323215961, 0.010712152346968651, 0.010389022529125214, 0.0051997629925608635, 0.00655410997569561, 0.011106332764029503, 0.0066652134992182255, } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&g0::quant11_zero, 3 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data13[16] = { -3487, -2331, 3818, 6272, 1407, 10910, -45, 12762, 5031, -4513, -937, 3063, 5364, -3420, 4769, -1450, };
const TfArray<16, float> quant13_scale = { 16, { 0.00017339646001346409, 0.00012174000585218892, 5.716819578083232e-05, 7.5934745837002993e-05, 0.00011226878996239975, 9.3308808573056012e-05, 8.8309745478909463e-05, 0.0001065389733412303, 0.00012017069093417376, 0.00014774181181564927, 0.00019724678713828325, 7.8964978456497192e-05, 0.00017590390052646399, 0.00023037348000798374, 0.00017296131409239024, 0.00018256083421874791, } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&g0::quant11_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data14[16*1*1*8] = { 
  /* [0][0][][] */ 127,99,85,-64,-47,-24,57,-42, 
  /* [1][0][][] */ 108,-26,-70,127,87,-68,36,74, 
  /* [2][0][][] */ -106,71,124,-37,25,127,-100,-7, 
  /* [3][0][][] */ -17,-42,-87,-96,19,127,-109,43, 
  /* [4][0][][] */ 35,-13,127,68,86,-118,0,60, 
  /* [5][0][][] */ 48,-127,-21,-108,45,-102,59,78, 
  /* [6][0][][] */ 85,-82,52,25,103,74,-127,-37, 
  /* [7][0][][] */ -37,15,-8,-60,-41,-127,-56,34, 
  /* [8][0][][] */ 41,10,-4,49,16,-127,31,2, 
  /* [9][0][][] */ -64,3,42,26,29,127,-28,126, 
  /* [10][0][][] */ -11,78,48,45,-127,40,-92,26, 
  /* [11][0][][] */ 46,51,-21,55,-1,8,95,-127, 
  /* [12][0][][] */ -33,13,-89,-127,40,-20,77,-36, 
  /* [13][0][][] */ -22,127,-26,29,61,-28,83,12, 
  /* [14][0][][] */ -127,-24,21,2,59,-86,-38,15, 
  /* [15][0][][] */ 50,-58,-24,-39,127,25,-45,-34, 
};
const TfArray<4, int> tensor_dimension14 = { 4, { 16,1,1,8 } };
const TfArray<16, float> quant14_scale = { 16, { 0.0066868457943201065, 0.0046947705559432507, 0.0022046291269361973, 0.002928340807557106, 0.0043295235373079777, 0.0035983526613563299, 0.0034055691212415695, 0.0041085593402385712, 0.0046342518180608749, 0.0056975018233060837, 0.0076066073961555958, 0.0030451982747763395, 0.0067835422232747078, 0.0088841021060943604, 0.0066700647585093975, 0.0070402598939836025, } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&g0::quant11_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data15[8] = { -3318, 842, 1524, 4518, 2614, 7705, -6220, 21, };
const TfArray<1, int> tensor_dimension15 = { 1, { 8 } };
const TfArray<8, float> quant15_scale = { 8, { 0.00014876789646223187, 0.00027978685102425516, 0.00063925929134711623, 0.00016616634093225002, 0.00023888848954811692, 0.0003212529409211129, 0.00022880149481352419, 0.00029701919993385673, } };
const TfArray<8, int> quant15_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data16[1*3*3*8] = { 
  /* [0][0][][] */ -12,11,-33,40,-53,-25,45,-21, 22,-26,-59,-119,-49,12,48,76, -14,79,118,-34,-12,5,61,24, 
  /* [0][1][][] */ -28,-127,4,127,-46,-127,127,21, 127,-3,7,-55,45,3,-39,21, 98,60,-15,-61,-17,-12,25,21, 
  /* [0][2][][] */ 76,-8,34,-10,-127,-40,94,-51, 78,87,30,109,86,-46,5,-8, 30,-63,-127,-110,-6,-28,22,-127, 
};
const TfArray<4, int> tensor_dimension16 = { 4, { 1,3,3,8 } };
const TfArray<8, float> quant16_scale = { 8, { 0.0065774302929639816, 0.01237013190984726, 0.028263378888368607, 0.0073466622270643711, 0.01056190486997366, 0.014203459955751896, 0.010115931741893291, 0.013132019899785519, } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&g0::quant15_zero, 3 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int32_t tensor_data17[8] = { 680, 3464, 21294, 7202, 5471, 5224, 4050, 5800, };
const TfArray<8, float> quant17_scale = { 8, { 0.00013447843957692385, 0.0001039248745655641, 2.9998018362675793e-05, 5.3498661145567894e-05, 8.1252379459328949e-05, 8.8961489382199943e-05, 9.6438838227186352e-05, 6.686519191134721e-05, } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&g0::quant15_zero, 0 };
const MODEL_SECTION(EI_MODEL_SECTION) ALIGN(16) int8_t tensor_data18[8*3*3*1] = { 
  /* [0][0][][] */ 28, 5, -55, 
  /* [0][1][][] */ 118, -98, -77, 
  /* [0][2][][] */ 127, -100, -36, 
  /* [1][0][][] */ -127, -31, -5, 
  /* [1][1][][] */ -72, -5, 36, 
  /* [1][2][][] */ -3, 45, 53, 
  /* [2][0][][] */ 49, 35, -71, 
  /* [2][1][][] */ 33, 99, -127, 
  /* [2][2][][] */ -7, 73, -78, 
  /* [3][0][][] */ -112, 115, -96, 
  /* [3][1][][] */ -115, 127, -40, 
  /* [3][2][][] */ -81, 95, 46, 
  /* [4][0][][] */ 55, -127, -57, 
  /* [4][1][][] */ 80, -69, -117, 
  /* [4][2][][] */ 72, 57, -29, 
  /* [5][0][][] */ 44, 72, -11, 
  /* [5][1][][] */ 0, 127, 35, 
  /* [5][2][][] */ -26, 45, 34, 
  /* [6][0][][] */ -19, 78, -41, 
  /* [6][1][][] */ 75, 75, -83, 
  /* [6][2][][] */ 127, -13, -41, 
  /* [7][0][][] */ 16, 127, 51, 
  /* [7][1][][] */ 76, 97, 77, 
  /* [7][2][][] */ 62, 20, 54, 
};
const TfArray<4, int> tensor_dimension18 = { 4, { 8,3,3,1 } };
const TfArray<8, float> quant18_scale = { 8, { 0.0030465978197753429, 0.0023544093128293753, 0.0006796026136726141, 0.0012120077153667808, 0.0018407658208161592, 0.0020154151134192944, 0.0021848138421773911, 0.0015148253878578544, } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&g0::quant15_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,49,13,1 } };
const TfArray<4, int> tensor_dimension20 = { 4, { 1,25,7,8 } };
const TfArray<1, float> quant20_scale = { 1, { 0.022617936134338379, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<1, float> quant21_scale = { 1, { 0.02593098022043705, } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<4, int> tensor_dimension22 = { 4, { 1,25,7,16 } };
const TfArray<1, float> quant22_scale = { 1, { 0.032347533851861954, } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<4, int> tensor_dimension23 = { 4, { 1,13,4,16 } };
const TfArray<1, float> quant23_scale = { 1, { 0.029875798150897026, } };
const TfLiteAffineQuantization quant23 = { (TfLiteFloatArray*)&quant23_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<4, int> tensor_dimension24 = { 4, { 1,13,4,24 } };
const TfArray<1, float> quant24_scale = { 1, { 0.029545176774263382, } };
const TfLiteAffineQuantization quant24 = { (TfLiteFloatArray*)&quant24_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<1, float> quant25_scale = { 1, { 0.044729415327310562, } };
const TfLiteAffineQuantization quant25 = { (TfLiteFloatArray*)&quant25_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<1, float> quant26_scale = { 1, { 0.13614942133426666, } };
const TfLiteAffineQuantization quant26 = { (TfLiteFloatArray*)&quant26_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<2, int> tensor_dimension27 = { 2, { 1,24 } };
const TfArray<1, float> quant27_scale = { 1, { 0.02263939380645752, } };
const TfLiteAffineQuantization quant27 = { (TfLiteFloatArray*)&quant27_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfArray<2, int> tensor_dimension28 = { 2, { 1,7 } };
const TfArray<1, float> quant28_scale = { 1, { 0.18478241562843323, } };
const TfArray<1, int> quant28_zero = { 1, { 20 } };
const TfLiteAffineQuantization quant28 = { (TfLiteFloatArray*)&quant28_scale, (TfLiteIntArray*)&quant28_zero, 0 };
const TfArray<1, float> quant29_scale = { 1, { 0.00390625, } };
const TfLiteAffineQuantization quant29 = { (TfLiteFloatArray*)&quant29_scale, (TfLiteIntArray*)&g0::quant20_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 19 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 2,2, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 19,18,17 } };
const TfArray<1, int> outputs1 = { 1, { 20 } };
const TfLiteDepthwiseConvParams opdata2 = { kTfLitePaddingSame, 1,1, 1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs2 = { 3, { 20,16,15 } };
const TfArray<1, int> outputs2 = { 1, { 21 } };
const TfLiteConvParams opdata3 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs3 = { 3, { 21,14,13 } };
const TfArray<1, int> outputs3 = { 1, { 22 } };
const TfLiteDepthwiseConvParams opdata4 = { kTfLitePaddingSame, 2,2, 1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs4 = { 3, { 22,12,11 } };
const TfArray<1, int> outputs4 = { 1, { 23 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 23,10,9 } };
const TfArray<1, int> outputs5 = { 1, { 24 } };
const TfLiteDepthwiseConvParams opdata6 = { kTfLitePaddingSame, 1,1, 1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs6 = { 3, { 24,8,7 } };
const TfArray<1, int> outputs6 = { 1, { 25 } };
const TfLiteConvParams opdata7 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs7 = { 3, { 25,6,5 } };
const TfArray<1, int> outputs7 = { 1, { 26 } };
const ALIGN(1) uint8_t opdata8[1] = { 0,  }; /* op type 40=MEAN */
const TfArray<2, int> inputs8 = { 2, { 26,2 } };
const TfArray<1, int> outputs8 = { 1, { 27 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 27,4,3 } };
const TfArray<1, int> outputs9 = { 1, { 28 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 28 } };
const TfArray<1, int> outputs10 = { 1, { 29 } };
};

TensorInfo_t tensorData[] = {
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension0, 637, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data1, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data2, (TfLiteIntArray*)&g0::tensor_dimension2, 8, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data3, (TfLiteIntArray*)&g0::tensor_dimension3, 28, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant3))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data4, (TfLiteIntArray*)&g0::tensor_dimension4, 168, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant4))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data5, (TfLiteIntArray*)&g0::tensor_dimension5, 96, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant5))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data6, (TfLiteIntArray*)&g0::tensor_dimension6, 576, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant6))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data7, (TfLiteIntArray*)&g0::tensor_dimension5, 96, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant7))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data8, (TfLiteIntArray*)&g0::tensor_dimension8, 216, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant8))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data9, (TfLiteIntArray*)&g0::tensor_dimension5, 96, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant9))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data10, (TfLiteIntArray*)&g0::tensor_dimension10, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant10))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data11, (TfLiteIntArray*)&g0::tensor_dimension11, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant11))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data12, (TfLiteIntArray*)&g0::tensor_dimension12, 144, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant12))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data13, (TfLiteIntArray*)&g0::tensor_dimension11, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant13))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data14, (TfLiteIntArray*)&g0::tensor_dimension14, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant14))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data15, (TfLiteIntArray*)&g0::tensor_dimension15, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant15))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data16, (TfLiteIntArray*)&g0::tensor_dimension16, 72, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant16))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data17, (TfLiteIntArray*)&g0::tensor_dimension15, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data18, (TfLiteIntArray*)&g0::tensor_dimension18, 72, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant18))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 1408), (TfLiteIntArray*)&g0::tensor_dimension19, 637, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension20, 1400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant20))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 2800), (TfLiteIntArray*)&g0::tensor_dimension20, 1400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension22, 2800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant22))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 2800), (TfLiteIntArray*)&g0::tensor_dimension23, 832, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant23))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension24, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant24))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 1248), (TfLiteIntArray*)&g0::tensor_dimension24, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant25))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension24, 1248, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant26))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 1344), (TfLiteIntArray*)&g0::tensor_dimension27, 24, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant27))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 16), (TfLiteIntArray*)&g0::tensor_dimension28, 7, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant28))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension28, 7, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant29))}, },
};

#ifndef TF_LITE_STATIC_MEMORY
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#else
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#endif

used_operators_e used_ops[] =
{OP_RESHAPE, OP_CONV_2D, OP_DEPTHWISE_CONV_2D, OP_CONV_2D, OP_DEPTHWISE_CONV_2D, OP_CONV_2D, OP_DEPTHWISE_CONV_2D, OP_CONV_2D, OP_MEAN, OP_FULLY_CONNECTED, OP_SOFTMAX, };


// Indices into tflTensors and tflNodes for subgraphs
const size_t tflTensors_subgraph_index[] = {0, 30, };
const size_t tflNodes_subgraph_index[] = {0, 11, };

// Input/output tensors
static const int in_tensor_indices[] = {
  0, 
};

static const int out_tensor_indices[] = {
  29, 
};


size_t current_subgraph_index = 0;

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = false;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}

typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;

static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
 
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  }

  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }

  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }
 
  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }

  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }

  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }

};


} // namespace

TfLiteStatus tflite_learn_822117_6_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  
  // Set microcontext as the context ptr
  ctx.impl_ = static_cast<void*>(&micro_context_);
  // Setup tflitecontext functions
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;

  ctx.tensors_size = 30;
  for (size_t i = 0; i < 30; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }

  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_DEPTHWISE_CONV_2D] = Register_DEPTHWISE_CONV_2D();
  registrations[OP_MEAN] = Register_MEAN();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].init) {
        tflNodes[i].user_data = registrations[used_ops[i]].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
      }
    }
  }
  current_subgraph_index = 0;

  for(size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].prepare) {
        ResetTensors();
        TfLiteStatus status = registrations[used_ops[i]].prepare(&ctx, &tflNodes[i]);
        if (status != kTfLiteOk) {
          return status;
        }
      }
    }
  }
  current_subgraph_index = 0;

  return kTfLiteOk;
}

TfLiteStatus tflite_learn_822117_6_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(in_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_822117_6_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(out_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_822117_6_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[used_ops[i]].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_822117_6_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
